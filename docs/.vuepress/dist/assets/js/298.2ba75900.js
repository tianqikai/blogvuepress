(window.webpackJsonp=window.webpackJsonp||[]).push([[298],{1665:function(e,_,v){"use strict";v.r(_);var r=v(26),o=Object(r.a)({},(function(){var e=this,_=e.$createElement,v=e._self._c||_;return v("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[v("h1",{attrs:{id:"_6-分布式"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_6-分布式"}},[e._v("#")]),e._v(" 6. 分布式")]),e._v(" "),v("h2",{attrs:{id:"_6-1-什么是cap理论"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_6-1-什么是cap理论"}},[e._v("#")]),e._v(" 6.1 什么是CAP理论")]),e._v(" "),v("p",[e._v("CAP理论是分布式领域中⾮常重要的⼀个指导理论，\n"),v("code",[e._v("C （Consistency） 表示强⼀致性")]),e._v("，\n"),v("code",[e._v("A （Availability） 表示可⽤性")]),e._v("，\n"),v("code",[e._v("P （Partition Tolerance） 表示分区容错性")]),e._v("，")]),e._v(" "),v("p",[e._v("CAP理论指出在⽬前的硬件条件下， ⼀个分布式系统是必须要保证分区容错性的， ⽽在这个前提下， 分布式系统要么保证CP， 要么保证AP， ⽆法同时保证CAP。")]),e._v(" "),v("ol",[v("li",[v("p",[e._v("分区容错性表示， ⼀个系统虽然是分布式的， 但是对外看上去应该是⼀个整体， 不能由于分布式系统内部的某个结点挂点， 或⽹络出现了故障， ⽽导致系统对外出现异常。所以， 对于分布式系统⽽⾔是⼀定\n要保证分区容错性的。")])]),e._v(" "),v("li",[v("p",[e._v("强⼀致性表示， ⼀个分布式系统中各个结点之间能及时的同步数据， 在数据同步过程中， 是不能对外提供服务的， 不然就会造成数据不⼀致， 所以强⼀致性和可⽤性是不能同时满⾜的。")])]),e._v(" "),v("li",[v("p",[e._v("可⽤性表示， ⼀个分布式系统对外要保证可⽤ 。")])])]),e._v(" "),v("h2",{attrs:{id:"_6-2-什么是base理论"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_6-2-什么是base理论"}},[e._v("#")]),e._v(" 6.2 什么是BASE理论")]),e._v(" "),v("p",[e._v("由于不能同时满⾜CAP， 所以出现了BASE理论：")]),e._v(" "),v("ol",[v("li",[e._v("BA：  Basically Available， 表示"),v("code",[e._v("基本可⽤， 表示可以允许⼀定程度的不可⽤")]),e._v("， ⽐如由于系统故障， 请求时间变⻓， 或者由于系统故障导致部分⾮核⼼功能不可⽤， 都是允许的")]),e._v(" "),v("li",[e._v("S：  Soft state：  表示"),v("code",[e._v("分布式系统可以处于⼀种中间状态")]),e._v("， ⽐如数据正在同步")]),e._v(" "),v("li",[e._v("E：  Eventually consistent， 表示"),v("code",[e._v("最终⼀致性")]),e._v("， 不要求分布式系统数据实时达到⼀致， 允许在经过⼀ 段时间后再达到⼀致， 在达到⼀致过程中， 系统也是可⽤的")])]),e._v(" "),v("h2",{attrs:{id:"_6-3-什么是rpc"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_6-3-什么是rpc"}},[e._v("#")]),e._v(" 6.3 什么是RPC")]),e._v(" "),v("p",[v("code",[e._v("RPC表示远程过程调⽤")]),e._v("， 对于Java这种⾯试对象语⾔， 也可以理解为远程⽅法调⽤")]),e._v(" "),v("p",[e._v("RPC调⽤和HTTP调⽤是有区别的， "),v("code",[e._v("RPC表示的是⼀种调⽤远程⽅法的⽅式， 可以使⽤HTTP协议 、或直接基于TCP 协议来实现RPC")]),e._v("。\n在Java中， 我们可以通过直接使⽤某个服务接⼝的代理对象来执⾏⽅法， ⽽底层则通 过构造HTTP请求来调⽤远端的⽅法， 所以， 有⼀种说法是"),v("code",[e._v("RPC协议是HTTP协议之上的⼀种协议")]),e._v("， 也是可以理解的。")]),e._v(" "),v("h2",{attrs:{id:"_6-4-分布式id是什么-有哪些解决方案"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_6-4-分布式id是什么-有哪些解决方案"}},[e._v("#")]),e._v(" 6.4 分布式ID是什么？ 有哪些解决⽅案？")]),e._v(" "),v("p",[e._v("在开发中， 我们通常会需要⼀个唯⼀ID来标识数据， 如果是单体架构， 我们可以通过数据库的主键， 或直接在内存中维护⼀个⾃增数字来作为ID都是可以的")]),e._v(" "),v("p",[e._v("但对于⼀个分布式系统， 就会有可能会出现ID冲突")]),e._v(" "),v("div",{staticClass:"custom-block tip"},[v("p",{staticClass:"custom-block-title"},[e._v("此时有以下解决⽅案：")]),e._v(" "),v("ol",[v("li",[e._v("uuid， 这种⽅案复杂度最低， 但是会影响存储空间和性能")]),e._v(" "),v("li",[e._v("利⽤"),v("code",[e._v("单机数据库的⾃增主键")]),e._v("， 作为分布式ID的⽣成器， 复杂度适中， ID⻓度较之uuid更短， 但是受到单机数据库性能的限制， 并发量⼤的时候， 此⽅案也不是最优⽅案")]),e._v(" "),v("li",[e._v("利⽤"),v("code",[e._v("redis、zookeeper的特性来⽣成id")]),e._v("， ⽐如"),v("code",[e._v("redis的⾃增命令")]),e._v("、"),v("code",[e._v("zookeeper的顺序节点")]),e._v("， 这种⽅案 和单机数据库(mysql)相⽐， 性能有所提⾼， 可以适当选⽤")]),e._v(" "),v("li",[v("code",[e._v("雪花算法")]),e._v("， ⼀切问题如果能直接⽤算法解决， 那就是最合适的， 利⽤雪花算法也可以⽣成分布式ID， 底层原理就是通过某台机器在某⼀毫秒内对某⼀个数字⾃增， 这种⽅案也能保证分布式架构中的系统id唯⼀， 但是只能保证趋势递增。业界存在tinyid、leaf等开源中间件实现了雪花算法。")])])]),e._v(" "),v("h2",{attrs:{id:"_6-5-分布式锁的使用场景是什么-有哪些实现方案"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_6-5-分布式锁的使用场景是什么-有哪些实现方案"}},[e._v("#")]),e._v(" 6.5 分布式锁的使⽤场景是什么？ 有哪些实现⽅案？")]),e._v(" "),v("blockquote",[v("p",[e._v("在单体架构中， 多个线程都是属于同⼀个进程的， 所以在线程并发执⾏时， 遇到资源竞争时， 可以利⽤ "),v("code",[e._v("ReentrantLock、synchronized")]),e._v("等技术来作为锁， 来控制共享资源的使⽤ 。")])]),e._v(" "),v("p",[e._v("⽽在分布式架构中， 多个线程是可能处于不同进程中的， ⽽这些线程并发执⾏遇到资源竞争时， 利⽤ReentrantLock、synchronized等技术是没办法来控制多个进程中的线程的， 所以需要分布式锁， 意思就是， 需要⼀个"),v("code",[e._v("分布式锁⽣成器")]),e._v("， 分布式系统中的应⽤程序都可以来使⽤这个⽣成器所提供的锁， 从⽽达到多个进程中的线程使⽤同⼀把锁。")]),e._v(" "),v("div",{staticClass:"custom-block tip"},[v("p",{staticClass:"custom-block-title"},[e._v("⽬前主流的分布式锁的实现⽅案有两种：")]),e._v(" "),v("ol",[v("li",[v("code",[e._v("zookeeper")]),e._v("：  "),v("strong",[e._v("利⽤的是zookeeper的临时节点、顺序节点、watch机制来实现的")]),e._v("， zookeeper分布式 锁的特点是⾼⼀致性， 因为zookeeper保证的是CP， 所以由它实现的分布式锁更可靠， 不会出现混乱")]),e._v(" "),v("li",[v("code",[e._v("redis")]),e._v("：  "),v("strong",[e._v("利⽤redis的setnx、lua脚本、消费订阅")]),e._v("等机制来实现的， redis分布式锁的特点是⾼可⽤ ， 因为redis保证的是AP， 所以由它实现的分布式锁可能不可靠， 不稳定 （⼀旦redis中的数据出现了 不⼀致） ， 可能会出现多个客户端同时加到锁的情况")])])]),e._v(" "),v("h2",{attrs:{id:"_6-6-什么是分布式事务-有哪些实现方案"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_6-6-什么是分布式事务-有哪些实现方案"}},[e._v("#")]),e._v(" 6.6 什么是分布式事务？ 有哪些实现⽅案？")]),e._v(" "),v("p",[e._v("在分布式系统中， ⼀次业务处理可能需要多个应⽤来实现， ⽐如⽤户发送⼀次下单请求， 就涉及到订单系统创建订单 、库存系统减库存， ⽽对于⼀次下单， 订单创建与减库存应该是要同时成功或同时失败的， 但在分布式系统中， 如果不做处理， 就很有可能出现订单创建成功， 但是减库存失败， 那么解决这 类问题， 就需要⽤到分布式事务 。")]),e._v(" "),v("div",{staticClass:"custom-block tip"},[v("p",{staticClass:"custom-block-title"},[e._v("常⽤解决⽅案有：")]),e._v(" "),v("ol",[v("li",[v("strong",[e._v("本地消息表")]),e._v("： 创建订单时， 将减库存消息加⼊在本地事务中， ⼀起提交到数据库存⼊本地消息表，\n然后调⽤库存系统， 如果调⽤成功则修改本地消息状态为成功， 如果调⽤库存系统失败， 则由后台定时任务从本地消息表中取出未成功的消息， 重试调⽤库存系统")]),e._v(" "),v("li",[v("strong",[e._v("消息队列")]),e._v("：  ⽬前RocketMQ中⽀持事务消息， 它的⼯作原理是：\n"),v("ul",[v("li",[e._v("a. ⽣产者订单系统先发送⼀条half消息到Broker， half消息对消费者⽽⾔是不可⻅的")]),e._v(" "),v("li",[e._v("b. 再创建订单， 根据创建订单成功与否， 向Broker发送commit或rollback")]),e._v(" "),v("li",[e._v("c. 并且⽣产者订单系统还可以提供Broker回调接⼝， 当Broker发现⼀段时间half消息没有收到任 何操作命令， 则会主动调此接⼝来查询订单是否创建成功")]),e._v(" "),v("li",[e._v("d. ⼀旦half消息commit了， 消费者库存系统就会来消费， 如果消费成功， 则消息销毁， 分布式事 务成功结束")]),e._v(" "),v("li",[e._v("e. 如果消费失败， 则根据重试策略进⾏重试， 最后还失败则进⼊死信队列， 等待进⼀步处理")])])]),e._v(" "),v("li",[v("strong",[e._v("Seata")]),e._v("：  阿⾥开源的分布式事务框架， ⽀持AT、TCC等多种模式， 底层都是基于两阶段提交理论来 实现的")])])]),e._v(" "),v("h2",{attrs:{id:"_6-7-什么是zab协议"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_6-7-什么是zab协议"}},[e._v("#")]),e._v(" 6.7 什么是ZAB协议")]),e._v(" "),v("p",[e._v("ZAB协议是Zookeeper⽤来"),v("code",[e._v("实现⼀致性的原⼦⼴播协议")]),e._v("， 该协议描述了Zookeeper是如何实现⼀致性的，")]),e._v(" "),v("div",{staticClass:"custom-block tip"},[v("p",{staticClass:"custom-block-title"},[e._v("分为三个阶段：")]),e._v(" "),v("ol",[v("li",[e._v("领导者选举阶段： 从Zookeeper集群中选出⼀个节点作为Leader， "),v("strong",[e._v("所有的写请求都会由Leader节点来处理")])]),e._v(" "),v("li",[e._v("数据同步阶段：  集群中所有节点中的数据要和Leader节点保持⼀致， 如果不⼀致则要进⾏同步")]),e._v(" "),v("li",[e._v("请求⼴播阶段：  当Leader节点接收到写请求时， 会利⽤两阶段提交来⼴播该写请求， 使得写请求像事务⼀样在其他节点上执⾏， 达到节点上的数据实时⼀致")])])]),e._v(" "),v("p",[e._v("但值得注意的是， "),v("strong",[e._v("Zookeeper只是尽量的在达到强⼀致性， 实际上仍然只是最终⼀致性的")]),e._v("。")]),e._v(" "),v("h2",{attrs:{id:"_6-8-为什么zookeeper可以用来作为注册中心"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_6-8-为什么zookeeper可以用来作为注册中心"}},[e._v("#")]),e._v(" 6.8 为什么Zookeeper可以⽤来作为注册中⼼")]),e._v(" "),v("p",[e._v("可以利⽤Zookeeper的临时节点和watch机制来实现注册中⼼的⾃动注册和发现， 另外Zookeeper中的  数据都是存在内存中的， 并且Zookeeper底层采⽤了nio， 多线程模型， 所以Zookeeper的性能也是⽐较 ⾼的， 所以可以⽤来作为注册中⼼， 但是如果考虑到注册中⼼应该是注册可⽤性的话， 那么Zookeeper  则不太合适， 因为Zookeeper是CP的， 它注重的是⼀致性， 所以集群数据不⼀致时， 集群将不可⽤， 所 以⽤Redis、Eureka、Nacos来作为注册中⼼将更合适。")]),e._v(" "),v("h2",{attrs:{id:"_6-9-zookeeper中的领导者选举的流程是怎样的"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_6-9-zookeeper中的领导者选举的流程是怎样的"}},[e._v("#")]),e._v(" 6.9 Zookeeper中的领导者选举的流程是怎样的？")]),e._v(" "),v("p",[e._v("对于Zookeeper集群， 整个集群需要从集群节点中选出⼀个节点作为Leader， ⼤体流程如下：")]),e._v(" "),v("ol",[v("li",[e._v("集群中各个节点⾸先都是观望状态 （LOOKING） ， ⼀开始都会投票给⾃⼰， 认为⾃⼰⽐较适合作 为leader")]),e._v(" "),v("li",[e._v("然后相互交互投票， 每个节点会收到其他节点发过来的选票， 然后pk， 先⽐较zxid， zxid⼤者获 胜， zxid如果相等则⽐较myid， myid⼤者获胜")]),e._v(" "),v("li",[e._v("⼀个节点收到其他节点发过来的选票， 经过PK后， 如果PK输了， 则改票， 此节点就会投给zxid或 myid更⼤的节点， 并将选票放⼊⾃⼰的投票箱中， 并将新的选票发送给其他节点")]),e._v(" "),v("li",[e._v("如果pk是平局则将接收到的选票放⼊⾃⼰的投票箱中")]),e._v(" "),v("li",[e._v("如果pk赢了， 则忽略所接收到的选票")]),e._v(" "),v("li",[e._v("当然⼀个节点将⼀张选票放⼊到⾃⼰的投票箱之后， 就会从投票箱中统计票数， 看是否超过⼀半的 节点都和⾃⼰所投的节点是⼀样的， 如果超过半数， 那么则认为当前⾃⼰所投的节点是leader")]),e._v(" "),v("li",[e._v("集群中每个节点都会经过同样的流程， pk的规则也是⼀样的， ⼀旦改票就会告诉给其他服务器， 所 以最终各个节点中的投票箱中的选票也将是⼀样的， 所以各个节点最终选出来的leader也是⼀样      的， 这样集群的leader就选举出来了")])]),e._v(" "),v("h2",{attrs:{id:"_6-10-zookeeper集群中节点之间数据是如何同步的"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_6-10-zookeeper集群中节点之间数据是如何同步的"}},[e._v("#")]),e._v(" 6.10 Zookeeper集群中节点之间数据是如何同步的")]),e._v(" "),v("ol",[v("li",[e._v("⾸先集群启动时， 会先进⾏领导者选举， 确定哪个节点是Leader， 哪些节点是Follower和Observer")]),e._v(" "),v("li",[e._v("然后Leader会和其他节点进⾏数据同步， 采⽤发送快照和发送Diff⽇志的⽅式")]),e._v(" "),v("li",[e._v("集群在⼯作过程中， 所有的写请求都会交给Leader节点来进⾏处理， 从节点只能处理读请求")]),e._v(" "),v("li",[e._v("Leader节点收到⼀个写请求时， 会通过两阶段机制来处理")]),e._v(" "),v("li",[e._v("Leader节点会将该写请求对应的⽇志发送给其他Follower节点， 并等待Follower节点持久化⽇志成 功")]),e._v(" "),v("li",[e._v("Follower节点收到⽇志后会进⾏持久化， 如果持久化成功则发送⼀个Ack给Leader节点")]),e._v(" "),v("li",[e._v("当Leader节点收到半数以上的Ack后， 就会开始提交， 先更新Leader节点本地的内存数据")]),e._v(" "),v("li",[e._v("然后发送commit命令给Follower节点， Follower节点收到commit命令后就会更新各⾃本地内存数 据")]),e._v(" "),v("li",[e._v("同时Leader节点还是将当前写请求直接发送给Observer节点， Observer节点收到Leader发过来的 写请求后直接执⾏更新本地内存数据")]),e._v(" "),v("li",[e._v("最后Leader节点返回客户端写请求响应成功")]),e._v(" "),v("li",[e._v("通过同步机制和两阶段提交机制来达到集群中节点数据⼀致")])]),e._v(" "),v("h2",{attrs:{id:"_6-11-dubbo支持哪些负载均衡策略"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_6-11-dubbo支持哪些负载均衡策略"}},[e._v("#")]),e._v(" 6.11 Dubbo⽀持哪些负载均衡策略")]),e._v(" "),v("ol",[v("li",[e._v("随机： 从多个服务提供者随机选择⼀个来处理本次请求， 调⽤量越⼤则分布越均匀， 并⽀持按权重 设置随机概率")]),e._v(" "),v("li",[e._v("轮询： 依次选择服务提供者来处理请求， 并⽀持按权重进⾏轮询， 底层采⽤的是平滑加权轮询算法")]),e._v(" "),v("li",[e._v("最⼩活跃调⽤数： 统计服务提供者当前正在处理的请求， 下次请求过来则交给活跃数最⼩的服务器 来处理")]),e._v(" "),v("li",[e._v("⼀致性哈希：  相同参数的请求总是发到同⼀个服务提供者")])]),e._v(" "),v("h2",{attrs:{id:"_6-12-dubbo是如何完成服务导出的"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_6-12-dubbo是如何完成服务导出的"}},[e._v("#")]),e._v(" 6.12 Dubbo是如何完成服务导出的？")]),e._v(" "),v("ol",[v("li",[e._v("⾸先Dubbo会将程序员所使⽤的@DubboService注解或@Service注解进⾏解析得到程序员所定义 的服务参数， 包括定义的服务名、服务接⼝ 、服务超时时间 、服务协议等等， 得到⼀个ServiceBean。")]),e._v(" "),v("li",[e._v("然后调⽤ServiceBean的export⽅法进⾏服务导出")]),e._v(" "),v("li",[e._v("然后将服务信息注册到注册中⼼， 如果有多个协议， 多个注册中⼼， 那就将服务按单个协议， 单个 注册中⼼进⾏注册")]),e._v(" "),v("li",[e._v("将服务信息注册到注册中⼼后， 还会绑定⼀些监听器， 监听动态配置中⼼的变更")]),e._v(" "),v("li",[e._v("还会根据服务协议启动对应的Web服务器或⽹络框架， ⽐如Tomcat、Netty等")])]),e._v(" "),v("h2",{attrs:{id:"_6-13-dubbo是如何完成服务引入的"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_6-13-dubbo是如何完成服务引入的"}},[e._v("#")]),e._v(" 6.13 Dubbo是如何完成服务引⼊的？")]),e._v(" "),v("ol",[v("li",[e._v("当程序员使⽤@Reference注解来引⼊⼀个服务时， Dubbo会将注解和服务的信息解析出来， 得到 当前所引⽤的服务名、服务接⼝是什么")]),e._v(" "),v("li",[e._v("然后从注册中⼼进⾏查询服务信息， 得到服务的提供者信息， 并存在消费端的服务⽬录中")]),e._v(" "),v("li",[e._v("并绑定⼀些监听器⽤来监听动态配置中⼼的变更")]),e._v(" "),v("li",[e._v("然后根据查询得到的服务提供者信息⽣成⼀个服务接⼝的代理对象， 并放⼊Spring容器中作为Bean")])]),e._v(" "),v("h2",{attrs:{id:"_6-14-dubbo的架构设计是怎样的"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_6-14-dubbo的架构设计是怎样的"}},[e._v("#")]),e._v(" 6.14 Dubbo的架构设计是怎样的？")]),e._v(" "),v("p",[e._v("Dubbo中的架构设计是⾮常优秀的， 分为了很多层次， 并且每层都是可以扩展的， ⽐如：")]),e._v(" "),v("ol",[v("li",[e._v("Proxy服务代理层， ⽀持JDK动态代理、javassist等代理机制")]),e._v(" "),v("li",[e._v("Registry注册中⼼层， ⽀持Zookeeper、Redis等作为注册中⼼")]),e._v(" "),v("li",[e._v("Protocol远程调⽤层， ⽀持Dubbo、Http等调⽤协议")]),e._v(" "),v("li",[e._v("Transport⽹络传输层， ⽀持netty、mina等⽹络传输框架")]),e._v(" "),v("li",[e._v("Serialize数据序列化层， ⽀持JSON、Hessian等序列化机制")])]),e._v(" "),v("p",[e._v("各层说明\n●    config 配置层： 对外配置接⼝， 以为中⼼， 可以直接\n初始化配置类， 也可以通过 spring 解析配置⽣成配置类\n●    proxy 服务代理层： 服务接⼝透明代理， ⽣成服务的客户端 Stub 和服务器端 Skeleton, 以\n为中⼼， 扩展接⼝为  ProxyFactory\n●    registry 注册中⼼层： 封装服务地址的注册与发现， 以服务 URL 为中⼼， 扩展接⼝为\nRegistry , RegistryService\n●    cluster 路由层： 封装多个提供者的路由及负载均衡， 并桥接注册中⼼， 以 Invoker 为中⼼， 扩 展接⼝为                                                                    LoadBalance\n●    monitor 监控层： RPC 调⽤次数和调⽤时间监控， 以 为中⼼， 扩展接⼝为  Monitor , MonitorService\n●    protocol 远程调⽤层： 封装 RPC 调⽤， 以 Result 为中⼼， 扩展接⼝为  Invoker , Exporter\n●    exchange 信息交换层： 封装请求响应模式， 同步转异步， 以 Request , Response 为中⼼， 扩\n展接⼝为")]),e._v(" "),v("p",[e._v("●    transport ⽹络传输层： 抽象 mina 和 netty 为统⼀接⼝， 以\nTransporter , Client , Server , Codec\n●    serialize 数据序列化层： 可复⽤的⼀些⼯具， 扩展接⼝为  Serialization , ObjectInput ,")]),e._v(" "),v("p",[e._v("关系说明\n●    在 RPC 中， Protocol 是核⼼层， 也就是只要有 Protocol + Invoker + Exporter 就可以完成⾮透明 的 RPC 调⽤， 然后在 Invoker 的主过程上 Filter 拦截点。\n●    图中的 Consumer 和 Provider 是抽象概念， 只是想让看图者更直观的了解哪些类分属于客户端与 服务器端， 不⽤ Client 和 Server 的原因是 Dubbo 在很多场景下都使⽤  Provider, Consumer,     Registry, Monitor 划分逻辑拓普节点， 保持统⼀概念。\n●    ⽽ Cluster 是外围概念， 所以 Cluster 的⽬的是将多个 Invoker 伪装成⼀个 Invoker， 这样其它⼈ 只要关注 Protocol 层 Invoker 即可， 加上 Cluster 或者去掉 Cluster 对其它层都不会造成影响 ， 因为只有⼀个提供者时， 是不需要 Cluster 的。\n●    Proxy 层封装了所有接⼝的透明化代理， ⽽在其它层都以 Invoker 为中⼼， 只有到了暴露给⽤户使 ⽤时， 才⽤  Proxy 将 Invoker 转成接⼝， 或将接⼝实现转成 Invoker， 也就是去掉 Proxy 层 RPC  是可以 Run 的， 只是不那么透明， 不那么看起来像调本地服务⼀样调远程服务。\n●    ⽽ Remoting 实现是 Dubbo 协议的实现， 如果你选择 RMI 协议， 整个 Remoting 都不会⽤上，  Remoting 内部再划为 Transport 传输层和 Exchange 信息交换层， Transport 层只负责单向消息\n传输， 是对 Mina, Netty, Grizzly 的抽象， 它也可以扩展 UDP 传输， ⽽ Exchange 层是在传输层 之上封装了 Request-Response 语义。\n●    Registry 和 Monitor 实际上不算⼀层， ⽽是⼀个独⽴的节点， 只是为了全局概览， ⽤层的⽅式画在 ⼀起。")]),e._v(" "),v("h2",{attrs:{id:"_6-15-spring-cloud有哪些常用组件-作用是什么"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_6-15-spring-cloud有哪些常用组件-作用是什么"}},[e._v("#")]),e._v(" 6.15 Spring Cloud有哪些常⽤组件， 作⽤是什么？")]),e._v(" "),v("ol",[v("li",[e._v("Eureka：  注册中⼼")]),e._v(" "),v("li",[e._v("Nacos： 注册中⼼ 、配置中⼼")]),e._v(" "),v("li",[e._v("Consul：  注册中⼼ 、配置中⼼")]),e._v(" "),v("li",[e._v("Spring Cloud Config：  配置中⼼")]),e._v(" "),v("li",[e._v("Feign/OpenFeign：  RPC调⽤")]),e._v(" "),v("li",[e._v("Kong：  服务⽹关")]),e._v(" "),v("li",[e._v("Zuul：  服务⽹关")]),e._v(" "),v("li",[e._v("Spring Cloud Gateway：  服务⽹关")]),e._v(" "),v("li",[e._v("Ribbon：  负载均衡")]),e._v(" "),v("li",[e._v("Spring CLoud Sleuth：  链路追踪")]),e._v(" "),v("li",[e._v("Zipkin：  链路追踪")]),e._v(" "),v("li",[e._v("Seata：  分布式事务")]),e._v(" "),v("li",[e._v("Dubbo： RPC调⽤")]),e._v(" "),v("li",[e._v("Sentinel：  服务熔断")]),e._v(" "),v("li",[e._v("Hystrix： 服务熔断")])]),e._v(" "),v("h2",{attrs:{id:"_6-16-spring-cloud和dubbo有哪些区别"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_6-16-spring-cloud和dubbo有哪些区别"}},[e._v("#")]),e._v(" 6.16 Spring Cloud和Dubbo有哪些区别？")]),e._v(" "),v("p",[e._v("Spring Cloud是⼀个微服务框架， 提供了微服务领域中的很多功能组件， Dubbo⼀开始是⼀个RPC调⽤框架， 核⼼是解决服务调⽤间的问题， Spring Cloud是⼀个⼤⽽全的框架， Dubbo则更侧重于服务调⽤， 所以Dubbo所提供的功能没有Spring Cloud全⾯， 但是Dubbo的服务调⽤性能⽐Spring Cloud⾼， 不过Spring Cloud和Dubbo并不是对⽴的， 是可以结合起来⼀起使⽤的。")]),e._v(" "),v("h2",{attrs:{id:"_6-17-什么是服务雪崩-什么是服务限流"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_6-17-什么是服务雪崩-什么是服务限流"}},[e._v("#")]),e._v(" 6.17 什么是服务雪崩？ 什么是服务限流？")]),e._v(" "),v("ol",[v("li",[e._v("当服务A调⽤服务B， 服务B调⽤C， 此时⼤量请求突然请求服务A， 假如服务A本身能抗住这些请求， 但是如果服务C抗不住， 导致服务C请求堆积， 从⽽服务B请求堆积， 从⽽服务A不可⽤， 这就是服务雪崩， 解决⽅式就是服务降级和服务熔断。")]),e._v(" "),v("li",[e._v("服务限流是指在⾼并发请求下， 为了保护系统， 可以对访问服务的请求进⾏数量上的限制， 从⽽防 ⽌系统不被⼤量请求压垮， 在秒杀中， 限流是⾮常重要的。")])]),e._v(" "),v("h2",{attrs:{id:"_6-18-什么是服务熔断-什么是服务降级-区别是什么"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_6-18-什么是服务熔断-什么是服务降级-区别是什么"}},[e._v("#")]),e._v(" 6.18 什么是服务熔断？ 什么是服务降级？ 区别是什么？")]),e._v(" "),v("ol",[v("li",[e._v("服务熔断是指， 当服务A调⽤的某个服务B不可⽤时， 上游服务A为了保证⾃⼰不受影响， 从⽽不再调⽤服务B， 直接返回⼀个结果， 减轻服务A和服务B的压⼒， 直到服务B恢复。")]),e._v(" "),v("li",[e._v("服务降级是指， 当发现系统压⼒过载时， 可以通过关闭某个服务， 或限流某个服务来减轻系统压⼒， 这就是服务降级。")])]),e._v(" "),v("blockquote",[v("p",[e._v("相同点：")])]),e._v(" "),v("ol",[v("li",[e._v("都是为了防⽌系统崩溃")]),e._v(" "),v("li",[e._v("都让⽤户体验到某些功能暂时不可⽤")])]),e._v(" "),v("blockquote",[v("p",[e._v("不同点： 熔断是下游服务故障触发的， 降级是为了降低系统负载")])]),e._v(" "),v("h2",{attrs:{id:"_6-20-soa、分布式、微服务之间有什么关系和区别"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_6-20-soa、分布式、微服务之间有什么关系和区别"}},[e._v("#")]),e._v(" 6.20 SOA、分布式、微服务之间有什么关系和区别？")]),e._v(" "),v("ol",[v("li",[e._v("分布式架构是指将单体架构中的各个部分拆分， 然后部署不同的机器或进程中去， SOA和微服务基本上都是分布式架构的")]),e._v(" "),v("li",[e._v("SOA是⼀种⾯向服务的架构， 系统的所有服务都注册在总线上， 当调⽤服务时， 从总线上查找服务 信息， 然后调⽤")]),e._v(" "),v("li",[e._v("微服务是⼀种更彻底的⾯向服务的架构， 将系统中各个功能个体抽成⼀个个⼩的应⽤程序， 基本保持⼀个应⽤对应的⼀个服务的架构")])])])}),[],!1,null,null,null);_.default=o.exports}}]);
# 1. redis集群方案

## **哨兵模式**：
sentinel，哨兵是 redis 集群中非常重要的一个组件，主要有以下功能：
集群监控：负责监控 redis master 和 slave 进程是否正常工作。
消息通知：如果某个 redis 实例有故障，那么哨兵负责发送消息作为报警通知给管理员。
故障转移：如果 master node 挂掉了，会自动转移到 slave node 上。
配置中心：如果故障转移发生了，通知 client 客户端新的 master 地址。
哨兵用于实现 redis 集群的高可用，本身也是分布式的，作为一个哨兵集群去运行，互相协同工作。
故障转移时，判断一个 master node 是否宕机了，需要大部分的哨兵都同意才行，涉及到了分布
式选举
即使部分哨兵节点挂掉了，哨兵集群还是能正常工作的
哨兵通常需要 3 个实例，来保证自己的健壮性。
`哨兵 + redis 主从的部署架构，是不保证数据零丢失的，只能保证 redis 集群的高可用性`。
对于哨兵 + redis 主从这种复杂的部署架构，尽量在测试环境和生产环境，都进行充足的测试和演练。

## Redis Cluster是一种服务端Sharding技术，
3.0版本开始正式提供。采用slot(槽)的概念，一共分成
16384个槽。将请求发送到任意节点，接收到请求的节点会将查询请求发送到正确的节点上执行

方案说明
通过哈希的方式，将数据分片，每个节点均分存储一定哈希槽(哈希值)区间的数据，默认分配了16384 个槽位

每份数据分片会存储在多个互为主从的多节点上
数据写入先写主节点，再同步到从节点(支持配置为阻塞同步)
同一分片多个节点间的数据不保持强一致性
读取数据时，当客户端操作的key没有分配在该节点上时，redis会返回转向指令，指向正确的节点
扩容时需要需要把旧节点的数据迁移一部分到新节点
在 redis cluster 架构下，每个 redis 要放开两个端口号，比如一个是 6379，另外一个就是 加1w 的端口号，比如 16379。
16379 端口号是用来进行节点间通信的，也就是 cluster bus 的通信，用来进行故障检测、配置更新、
故障转移授权。cluster bus 用了另外一种二进制的协议，gossip 协议，用于节点间进行高效的数据交换，占用更少的网络带宽和处理时间。

**优点**
无中心架构，支持动态扩容，对业务透明
具备Sentinel的监控和自动Failover(故障转移)能力
客户端不需要连接集群所有节点，连接集群中任何一个可用节点即可
高性能，客户端直连redis服务，免去了proxy代理的损耗
**缺点**
运维也很复杂，数据迁移需要人工干预
只能使用0号数据库
不支持批量操作(pipeline管道操作)
分布式逻辑和存储模块耦合等
Redis Sharding是Redis Cluster出来之前，业界普遍使用的多Redis实例集群方法。其主要思想是采用
哈希算法将Redis数据的key进行散列，通过hash函数，特定的key会映射到特定的Redis节点上。Java
redis客户端驱动jedis，支持Redis Sharding功能，即ShardedJedis以及结合缓存池的

`ShardedJedisPool`
**优点**
优势在于非常简单，服务端的Redis实例彼此独立，相互无关联，每个Redis实例像单服务器一样运行，
非常容易线性扩展，系统的灵活性很强
**缺点**
由于sharding处理放到客户端，规模进一步扩大时给运维带来挑战。
客户端sharding不支持动态增删节点。服务端Redis实例群拓扑结构有变化时，每个客户端都需要更新调整。连接不能共享，当应用规模增大时，资源浪费制约优化

------------------------------------------

# 2. 如何避免缓存雪崩，缓存（失效）击穿，缓存穿透

缓存雪崩可以采用：
cluter集群方式部署，将热点数据分布在不同的节点上

1. 热点数据永不过期

2. 使用限流、熔断技术

---------------------------------

## 缓存雪崩
是指缓存同一时间大面积的失效，所以后面的请求都会落到数据库上，造成数据库短时间内承受大量请求而崩掉。

:::tip 解决方案：
1. 缓存数据的过期时间设置随机，防止同一时间大量数据过期现象发生。

2. 给每一个缓存数据增加相应的缓存标记，记录缓存是否失效，如果缓存标记失效，则更新数据缓存。

3. 缓存预热:服务器启动前先把热点数据缓存到redis中

4. 互斥锁

5. 请求限流
6. redis-cluter集群模式
:::

## 缓存穿透
是指缓存和数据库中都没有的数据，导致所有的请求都落到数据库上，造成数据库短时间内承受大量请求而崩掉。

:::tip 解决方案：
1. 接口层增加校验，如用户鉴权校验，id做基础校验，id<=0的直接拦截；

2. 从缓存取不到的数据，在数据库中也没有取到，这时也可以将key-value对写为key-null，缓存有效时间可以设置短点，如30秒（设置太长会导致正常情况也没法使用）。这样可以防止攻击用户反复用同一个id暴力攻击

3. 采用布隆过滤器，将所有可能存在的数据哈希到一个足够大的 bitmap 中，一个一定不存在的数据会被这个 bitmap 拦截掉，从而避免了对底层存储系统的查询压力
:::

## 缓存击穿
是指缓存中没有但数据库中有的数据（一般是缓存时间到期），这时由于并发用户特别多，同时读缓存没读到数据，又同时去数据库去取数据，引起数据库压力瞬间增大，造成过大压力。和缓存雪
崩不同的是，缓存击穿指并发查同一条数据，缓存雪崩是不同数据都过期了，很多数据都查不到从而查数据库。

:::tip 解决方案
1. 设置热点数据永远不过期

2. 加互斥锁
:::


# 3. Redis和Mysql如何保证数据⼀致 

1、如果先删缓存，再写数据库： 

在高并发场景下，当第一个线程删除了缓存，还没有来得及写数据库，第二个线程来读取数据，会发现缓存中的数据为空，那就会去读数据库中的数据(旧值，脏数据)，读完之后，把读到的结果写入缓存(此时，第一个线程已经将新的值写到缓存里面了)，这样缓存中的值就会被覆盖为修改前的脏数据。

总结：在这种方式下，通常要求写操作不会太频繁。
解决方案：
1》**先操作缓存，但是不删除缓存。将缓存修改为一个特殊值(-999)**。
客户端读缓存时，发现是默认值，就休眠一小会，再去查一次Redis。 -》 特殊值对业务有侵入。 休眠时间，**可能会多次重复，对性能有影响**。

2》**延时双删**。 

先删除缓存，然后再写数据库，休眠一小会，再次删除缓存。-》 如果数据写操作很频繁，同样还是会有脏数据的问题。
2、先写数据库，再删缓存： 如果数据库写完了之后，缓存删除失败，数据就会不一致。
总结： 始终只能保证一定时间内的最终一致性。

解决方案：
1》给缓存设置一个过期时间 问题：过期时间内，缓存数据不会更新。
2》**引入MQ，保证原子操作**
解决方案：将热点数据缓存设置为永不过期，但是在value当中写入一个逻辑上的过期时间，另外起一个后台线程，扫描这些key，对于已逻辑上过期的缓存，进行删除。

# 4. redis 主从复制的核心原理

通过执行slaveof命令或设置slaveof选项，让一个服务器去复制另一个服务器的数据。主数据库可以进
行读写操作，当写操作导致数据变化时会自动将数据同步给从数据库。而从数据库一般是只读的，并接
受主数据库同步过来的数据。一个主数据库可以拥有多个从数据库，而一个从数据库只能拥有一个主数
据库。

全量复制：
（1）主节点通过bgsave命令fork子进程进行`RDB持久化`，该过程是非常消耗CPU、内存(页表复制)、硬盘IO的 

（2）主节点通过网络将`RDB文件`发送给从节点，对主从节点的带宽都会带来很大的消耗

（3）从节点清空老数据、载入新RDB文件的过程是阻塞的，无法响应客户端的命令；如果从节点执行bgrewriteaof，也会带来额外的消耗


部分复制：
1. 复制偏移量：执行复制的双方，主从节点，分别会维护一个复制偏移量offset
2. 复制积压缓冲区：主节点内部维护了一个固定长度的、先进先出(FIFO)队列 作为复制积压缓冲区，当主从节点offset的差距过大超过缓冲区长度时，将无法执行部分复制，只能执行全量复制。
3. 服务器运行ID(runid)：每个Redis节点，都有其运行ID，运行ID由节点在启动时自动生成，主节点会将自己的运行ID发送给从节点，从节点会将主节点的运行ID存起来。 从节点Redis断开重连的时候，就是根据运行ID来判断同步的进度：

如果从节点保存的runid与主节点现在的runid相同，说明主从节点之前同步过，主节点会继续尝试使用部分复制(到底能不能部分复制还要看offset和复制积压缓冲区的情况)；
如果从节点保存的runid与主节点现在的runid不同，说明从节点在断线前同步的Redis节点并不是当前的主节点，只能进行全量复制。

# 5. Redis分布式锁

**分布式锁的本质**：就是在所有进程都能访问到的一个地方，设置一个锁资源，让这些进程都来竞争锁资源。`数据库、zookeeper、 Redis`。通常对于分布式锁，会要求响应快、性能高、与业务无关。

1. `SETNX 加锁`

2. `redission+setnx`

**前两种情况可能会出现锁的丢失情况**

3. `redission的redlock锁`

# 6. Redis的数据结构及使⽤场景 Redis的数据结构有： 
1. `字符串`：可以⽤来做最简单的数据缓存，可以缓存某个简单的字符串，也可以缓存某个json格式的字符 串，Redis分布式锁的实现就利⽤了这种数据结构，还包括可以实现计数器、Session共享、分布式ID 
2. `哈希表`：可以⽤来存储⼀些key-value对，更适合⽤来存储对象 
3. `列表`：Redis的列表通过命令的组合，既可以当做栈，也可以当做队列来使⽤，可以⽤来缓存类似微信 公众号、微博等消息流数据 
4. `集合`：和列表类似，也可以存储多个元素，但是不能重复，集合可以进⾏交集、并集、差集操作，从⽽ 可以实现类似，我和某⼈共同关注的⼈、朋友圈点赞等功能 
5. `有序集合`：集合是⽆序的，有序集合可以设置顺序，可以⽤来实现排⾏榜功能

String：字符串
List：列表
Hash：哈希表
Set：无序集合
Sorted Set：有序集合
bitmap：布隆过滤器
GeoHash：坐标，借助Sorted Set实现，通过zset的score进行排序就可以得到坐标附近的其它元素，
通过将score还原成坐标值就可以得到元素的原始坐标
HyperLogLog：统计不重复数据，用于大数据基数统计
Streams：内存版的kafka

# 7. Redis缓存过期策略

`定时过期`：每个设置过期时间的key都需要创建一个定时器，到过期时间就会立即清除。该策略可以立即清除过期的数据，对内存很友好；但是会占用大量的CPU资源去处理过期的数据，从而影响缓存的响应时间和吞吐量

`惰性过期`：只有当访问一个key时，才会判断该key是否已过期，过期则清除。该策略可以最大化地节省CPU资源，但是很消耗内存、许多的过期数据都还存在内存中。极端情况可能出现大量的过期key没有再次被访问，从而不会被清除，占用大量内存。

`定期过期`：每隔一定的时间，会扫描一定数量的数据库的expires字典中一定数量的key（是随机的），并清除其中已过期的key。该策略是定时过期和惰性过期的折中方案。通过调整定时扫描的时间间隔和每次扫描的限定耗时，可以在不同情况下使得CPU和内存资源达到最优的平衡效果。

`分桶策略`：`定期过期的优化`，将过期时间点相近的key放在一起，按时间扫描分桶。

## 定时删除

含义：在设置key的过期时间的同时，为该key创建一个定时器，让定时器在key的过期时间来临时，对key进行删除

优点：保证内存被尽快释放

缺点：
若过期key很多，删除这些key会占用很多的CPU时间，在CPU时间紧张的情况下，CPU不能把所有的时间用来做要紧的事儿，还需要去花时间删除这些key定时器的创建耗时，若为每一个设置过期时间的key创建一个定时器（将会有大量的定时器产生），性能影响严重没人用

## 惰性删除

含义：`key过期的时候不删除，每次从数据库获取key的时候去检查是否过期，若过期，则删除，返回null`

优点：删除操作只发生在从数据库取出key的时候发生，而且只删除当前key，所以对CPU时间的占用是比较少的，而且此时的删除是已经到了非做不可的地步（如果此时还不删除的话，我们就会获取到了已经过期的key了）

缺点：`若大量的key在超出超时时间后，很久一段时间内，都没有被访问过，那么可能发生内存泄露（无用的垃圾占用了大量的内存）`

## 定期删除
含义：`每隔一段时间执行一次删除(在redis.conf配置文件设置hz，1s刷新的频率)过期key操作`

优点：
通过限制删除操作的时长和频率，来减少删除操作对CPU时间的占用--处理"定时删除"的缺点
定期删除过期key--处理"惰性删除"的缺点

缺点
在内存友好方面，不如"定时删除"
在CPU时间友好方面，不如"惰性删除"

难点
合理设置删除操作的执行时长（每次删除执行多长时间）和执行频率（每隔多长时间做一次删除）（这个要根据服务器运行情况来定了）
看完上面三种策略后可以得出以下结论：

定时删除和定期删除为主动删除：Redis会定期主动淘汰一批已过去的key

惰性删除为被动删除：用到的时候才会去检验key是不是已过期，过期就删除

惰性删除为redis服务器内置策略

定期删除可以通过：

第一、配置redis.conf 的hz选项，默认为10 （即1秒执行10次，100ms一次，值越大说明刷新频率越快，最Redis性能损耗也越大） 
第二、配置redis.conf的maxmemory最大值，当已用内存超过maxmemory限定时，就会触发主动清理策略

# 8. 分布式系统中常用的缓存方案有哪些
客户端缓存：页面和浏览器缓存，APP缓存，H5缓存，localStorage 和 sessionStorage
CDN缓存：内容存储：数据的缓存，内容分发：负载均衡
nginx缓存：静态资源
服务端缓存：本地缓存，外部缓存
数据库缓存：持久层缓存（mybatis，hibernate多级缓存），mysql查询缓存
操作系统缓存：Page Cache、Buffer Cache

# 9. 常见的缓存淘汰算法

`FIFO（First In First Out，先进先出）`，根据缓存被存储的时间，离当前最远的数据优先被淘汰；
`LRU（Least Recently Used，最近最少使用）`，根据最近被使用的时间，离当前最远的数据优先被淘汰；
`LFU（Least Frequently Used，最不经常使用）`，在一段时间内，缓存数据被使用次数最少的会被淘汰。

# 10. redis的持久化机制

RDB：Redis DataBase 将某一个时刻的内存快照（Snapshot），以二进制的方式写入磁盘。
手动触发：
save命令，使 Redis 处于阻塞状态，直到 RDB 持久化完成，才会响应其他客户端发来的命令，所
以在生产环境一定要慎用
bgsave命令，fork出一个子进程执行持久化，主进程只在fork过程中有短暂的阻塞，子进程创建
之后，主进程就可以响应客户端请求了
自动触发：
save m n ：在 m 秒内，如果有 n 个键发生改变，则自动触发持久化，通过bgsave执行，如果设
置多个、只要满足其一就会触发，配置文件有默认配置(可以注释掉)
flushall：用于清空redis所有的数据库，flushdb清空当前redis所在库数据(默认是0号数据库)，会
清空RDB文件，同时也会生成dump.rdb、内容为空
主从同步：全量同步时会自动触发bgsave命令，生成rdb发送给从节点

优点：
1、整个Redis数据库将只包含一个文件 dump.rdb，方便持久化。
2、容灾性好，方便备份。
3、性能最大化，fork 子进程来完成写操作，让主进程继续处理命令，所以是 IO 最大化。使用单独子进
程来进行持久化，主进程不会进行任何 IO 操作，保证了 redis 的高性能
4.相对于数据集大时，比 AOF 的启动效率更高。

缺点：
1、数据安全性低。RDB 是间隔一段时间进行持久化，如果持久化之间 redis 发生故障，会发生数据丢
失。所以这种方式更适合数据要求不严谨的时候) 2、由于RDB是通过fork子进程来协助完成数据持久化工作的，因此，如果当数据集较大时，可能会导
致整个服务器停止服务几百毫秒，甚至是1秒钟。会占用cpu
AOF：Append Only File 以日志的形式记录服务器所处理的每一个写、删除操作，查询操作不会记
录，以文本的方式记录，可以打开文件看到详细的操作记录，调操作系统命令进程刷盘
1、所有的写命令会追加到 AOF 缓冲中。
2、AOF 缓冲区根据对应的策略向硬盘进行同步操作。
3、随着 AOF 文件越来越大，需要定期对 AOF 文件进行重写，达到压缩的目的。
4、当 Redis 重启时，可以加载 AOF 文件进行数据恢复。

同步策略：
每秒同步：异步完成，效率非常高，一旦系统出现宕机现象，那么这一秒钟之内修改的数据将会丢失
每修改同步：同步持久化，每次发生的数据变化都会被立即记录到磁盘中，最多丢一条
不同步：由操作系统控制，可能丢失较多数据
优点：
1、数据安全
2、通过 append 模式写文件，即使中途服务器宕机也不会破坏已经存在的内容，可以通过 redis-check-aof 工具解决数据一致性问题。
3、AOF 机制的 rewrite 模式。定期对AOF文件进行重写，以达到压缩的目的
缺点：
1、AOF 文件比 RDB 文件大，且恢复速度慢。
2、数据集大的时候，比 rdb 启动效率低。
3、运行效率没有RDB高
AOF文件比RDB更新频率高，优先使用AOF还原数据。
AOF比RDB更安全也更大
RDB性能比AOF好
如果两个都配了优先加载AOF


# 11 Redis线程模型、单线程快的原因

Redis基于Reactor模式开发了网络事件处理器，这个处理器叫做`文件事件处理器` file event handler。
这个文件事件处理器，它是单线程的，所以 Redis 才叫做单线程的模型，它采用IO多路复用机制来同时
监听多个Socket，根据Socket上的事件类型来选择对应的事件处理器来处理这个事件。可以实现高性能
的网络通信模型，又可以跟内部其他单线程的模块进行对接，保证了 Redis 内部的线程模型的简单性。


文件事件处理器的结构包含4个部分：多个Socket、IO多路复用程序、文件事件分派器以及事件处理器
（命令请求处理器、命令回复处理器、连接应答处理器等）。
多个 Socket 可能并发的产生不同的操作，每个操作对应不同的文件事件，但是IO多路复用程序会监听
多个 Socket，会将 Socket 放入一个队列中排队，每次从队列中取出一个 Socket 给事件分派器，事件分派器把 Socket 给对应的事件处理器。
然后一个 Socket 的事件处理完之后，IO多路复用程序才会将队列中的下一个 Socket 给事件分派器。文
件事件分派器会根据每个 Socket 当前产生的事件，来选择对应的事件处理器来处理。

-------------------------

单线程快的原因：
1）纯内存操作
2）核心是基于非阻塞的IO多路复用机制
3）单线程反而避免了多线程的频繁上下文切换带来的性能问题
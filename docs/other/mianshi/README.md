---
autoNext: JAVA基础-0
---

# 面试与解决方案整理
[[toc]]

**系统架构：设计模式+注解sop+数据结构**

## 设计模式

1. spring中用到的设计模式

- 单例模式
创建
创建bean的时候；如果不是原型bean，那么就进行bean的实例化到单例bean池中

jdbc用到的java的spi机制和策略模式

- 策略模式
聚合支付，微信支付，支付宝支付，超级网银等等

通过传过来的值去数据库和枚举值或者配置中心找到对应的类名，然后动态调用各个实现类

减少了**ifelse操作**

- 适配模式

开发了一套对接商品房接口，但是无法做到通用接口字段匹配。这时候

有很多家商品房机构过来对接，但是接口不匹配；可以进行继承父类进行适配处理，其实就是在核心开户流程外包一层

-----------------------

- 模板方法模式

比如转账流程都是一样的；
但是有个新接入的机构，需要加特殊处理，这时候就可以模板方法实现子类的**钩子方法**

----------------------------

- 职责链模式

审批流程时用的比较多

----------------------------

- 工厂模式

接口信息检查时，进行处理定义抽象类进行通用信息检查，然后每个接口子类继承抽象类
如果有特殊处理，那么就进行重写相关方法

-----------------------

## 并发编程

1. volatile

    - voliate关键字防止变量指令重排，保证有序性,`内存屏障`
    - 一个线程写，多个线程读时，能够保证变量的可见性 ,从`cpu缓冲区存到主内存中保证了数据可见性`

    - Volatile关键字只能保证线程可见性， 不能保证原子性。
    - Volatile防止指令重排。在DCL中，防止高并发情况下，指令重排造成的线程安全问题。
    -----------------------------------
    dcl单例模式 为什么使用voliate？
    对象创建过程不是一个原子性操作-> 类加载，分配内存，对象初始化，内存和对象关系对应;

2. threadlocal并发安全问题

    thread中存在一个map对象--`threadlocalmap`
    他们的生命周期一样长，而threadlocalmap的key值是threadlocal，key和threadlocal之间是弱应用。而且threadlocal的生命周期相对thread生命周期要短。

3. thread Runable区别
它们两者没什么可比性，runable是一个接口，thread实现了这个Runable接口，复杂任务处理可以使用Thread。

4. `Countdownlatch` ，`CyclicBarrier` ， `Semaphore`
countdownlatch : 采用计数器方式，一个线程依赖于其他线程，那么我可以使用coundownlatch的await进行等着。其他线程进行countdown处理
CyclicBarrier ：采用计数器方式，await方法进行内存堵塞。直到最后一个线程执行await，然后进行释放所有的阻塞线程
Semaphore ： 信号量处理

Semaphore表示信号量，可以设置许可的个数，表示同时允许最多多少个线程使⽤该信号量，通过acquire()来获取许可，如果没有许可可⽤则线程阻塞，并通过AQS来排队，可以通过release()ReentrantLock中tryLock()和lock()⽅法的区别CountDownLatch和Semaphore的区别和底层原理10⽅法来释放许可，当某个线程释放了某个许可后，会从AQS中正在排队的第⼀个线程开始依次唤醒，直到没有空闲许可


fork join

---------------------------------------------------------
5. ReetrantLock tryLock() lock()
  - tryLock()表示尝试加锁，可能加到，也可能加不到，该⽅法不会阻塞线程，如果加到锁则返回true，没有加到则返回false
  - lock()表示`阻塞加锁`，线程会阻塞直到加到锁，⽅法也没有返回值

6. ReentrantLock中的公平锁和⾮公平锁的底层实现

- 公平锁是指lock加锁时，如果是公平锁，那么就先检查AQS队列是否有线程在排队，如果没有加锁成功，如果有加锁失败，入队处理；
- 非公平锁是指，在锁的竞争时，我不去判断队列中有没有线程在等待，我直接去竞争锁

不管是公平锁还是⾮公平锁，⼀旦没竞争到锁，都会进⾏排队，当锁释放时，都是唤醒排在最前⾯的线程

7. sleep 、notify 、wait 、yield join

sleep 是不依赖于synchronized，但是wait需要依赖synchronized
sleep不需要被唤醒，但是wait需要
notify执行后，会释放锁的，去获取锁

join执行完后，线程将进入阻塞状态，知道阻塞线程执行完
    **线程之间如何进⾏通讯的**
    1. 线程之间可以通过共享内存或基于⽹络来进⾏通信 
    2. 如果是通过共享内存来进⾏通信，则需要考虑并发问题，什么时候阻塞，什么时候唤醒 
    3. 像Java中的wait()、notify()就是阻塞和唤醒 
    4. 通过⽹络就⽐较简单了，通过⽹络连接将通信数据发送给对⽅，当然也要考虑到并发问题，处理⽅式就 是加锁等⽅式

8. sychronized的偏向锁、轻量级锁、重量级锁
 - 无锁状态： 0 01
 - 偏向锁 在锁对象的对象头中记录⼀下当前获取到该锁的线程ID，该线程下次如果⼜来获取该锁就可以直接获取到了 1 01
 - 轻量级锁 null 00 
 - 重量级锁 null 01
 - 锁的逃逸分析

9. OOP 


10. Sychronized和ReentrantLock的区别 
    1. sychronized是⼀个关键字，ReentrantLock是⼀个类 
    2. sychronized会⾃动的加锁与释放锁，ReentrantLock需要程序员⼿动加锁与释放锁 
    3. sychronized的底层是JVM层⾯的锁，ReentrantLock是API层⾯的锁 
    4. sychronized是⾮公平锁，ReentrantLock可以选择公平锁或⾮公平锁 
    5. sychronized锁的是对象，锁信息保存在对象头中，ReentrantLock通过代码中int类型的state标识 来标识锁的状态 
    6. sychronized底层有⼀个锁升级的过程

11. ThreadLocal的原理和使用场景

    - 在进行对象跨层传递的时候，使用ThreadLocal可以避免多次传递，打破层次间的约束。
    - 线程间数据隔离
    - 进行事务操作，用于存储线程事务信息。
    - 数据库连接，Session会话管理。
    ThreadLocal正确的使用方法
     - 每次使用完ThreadLocal都调用它的remove()方法清除数据
     - 将ThreadLocal变量定义成private static，这样就一直存在ThreadLocal的强引用，也就能保证任何时候都能通过ThreadLocal的弱引用访问到Entry的value值，进而清除掉 。

12. 三大原则
  - 原子性  i++
    ```    
    1：将 count 从主存读到工作内存中的副本中
    2：+1的运算
    3：将结果写入工作内存
    4：将工作内存的值刷回主存(什么时候刷入由操作系统决定，不确定的)
    ```
  - 可见性
  - 有序性
  关键字：volatile、synchronized、final

13. 如何查看线程死锁
  - java应用可以通过jstack命令进行查看，jstack命令中会显示发生了死锁过程
  - 两个线程去操作数据库时，数据库发⽣了死锁，这是可以查询数据库的死锁情况
  ```sql
     1. 查询是否锁表
     show OPEN TABLES where In_use > 0; 
     2. 查询进程 
     show processlist; 
     3. 查看正在锁的事务 
     SELECT * FROM INFORMATION_SCHEMA.INNODB_LOCKS; 
     4. 查看等待锁的事务 
     SELECT * FROM INFORMATION_SCHEMA.INNODB_LOCK_WAITS;
  ```
  :::tip Java死锁如何避免？
    1. 要注意`加锁顺序`，保证每个线程按同样的顺序进⾏加锁 
    2. 要注意加锁时限，可以针对所设置⼀个`超时时间 `
    3. 要注意死锁检查，这是⼀种预防机制，确保在第⼀时间发现死锁并进⾏解决
  :::


14. 如何保证线程安全
    加锁处理

15. 如何开启线程？ 
    1. 继承Thread类，重写run方法。 
    2. 实现Runnable接口，实现run方法。
    3. 实现Callable接口，实现call方法。通过FutureTask创建一个线程，获取到线程执行的返回值。
    4. 通过线程池来开启线程。
16. 怎么保证线程安全？ 
    加锁： 1. JVM提供的锁,也就是Synchronized关键字。

    2、 JDK提供的各种锁 Lock。


17. 谈谈你对AQS的理解。AQS如何实现可重入锁？

    - AQS是一个JAVA线程同步的框架。是JDK中很多锁工具的核心实现框架。
    - 在AQS中，维护了一个信号量state和一个线程组成的双向链表队列。其中，这个线程队列，就是用来给线程排队的，而state就像是一个红绿灯，用来控制线程排队或者放行的。 在不同的场景下，有不用的意义。
    - 在可重入锁这个场景下，state就用来表示加锁的次数。0标识无锁，每加一次锁，state就加1。释放锁state就减1。

18. 线程池
    **如果你提交任务时，线程池队列已满，这时会发⽣什么**

       - 如果使⽤的⽆界队列，那么可以继续提交任务时没关系的 
       - 如果使⽤的有界队列，提交任务时，如果队列满了，如果核⼼线程数没有达到上限，那么则增加线程， 如果线程数已经达到了最⼤值，则使⽤拒绝策略进⾏拒绝
    **简述线程池原理，FixedThreadPool⽤的阻塞队列是什么**
    1. 如果此时线程池中的数量⼩于corePoolSize，即使线程池中的线程都处于空闲状态，也要创建新的线 程来处理被添加的任务。 
    2. 如果此时线程池中的数量等于corePoolSize，但是缓冲队列workQueue未满，那么任务被放⼊缓冲队 列。 
    3. 如果此时线程池中的数量⼤于等于corePoolSize，缓冲队列workQueue满，并且线程池中的数量⼩于 maximumPoolSize，建新的线程来处理被添加的任务。
    4. 如果此时线程池中的数量⼤于corePoolSize，缓冲队列workQueue满，并且线程池中的数量等于 maximumPoolSize，那么通过 handler所指定的策略来处理此任务。 
    5. 当线程池中的线程数量⼤于 corePoolSize时，如果某线程空闲时间超过keepAliveTime，线程将被终 ⽌。这样，线程池可以动态的调整池中的线程数

    **线程池中阻塞队列的作用？为什么是先添加列队而不是先创建最大线程？**

    1、降低资源消耗；提高线程利用率，降低创建和销毁线程的消耗。
    2、提高响应速度；任务来了，直接有线程可用可执行，而不是先创建线程，再执行。
    3、提高线程的可管理性；线程是稀缺资源，使用线程池可以统一分配调优监控。


        1、一般的队列只能保证作为一个有限长度的缓冲区，如果超出了缓冲长度，就无法保留当前的任务
        了，阻塞队列通过阻塞可以保留住当前想要继续入队的任务。
        阻塞队列可以保证任务队列中没有任务时阻塞获取任务的线程，使得线程进入wait状态，释放cpu资
        源。
        阻塞队列自带阻塞和唤醒的功能，不需要额外处理，无任务执行时,线程池利用阻塞队列的take方法挂
        起，从而维持核心线程的存活、不至于一直占用cpu资源


        2、在创建新线程的时候，是要获取全局锁的，这个时候其它的就得阻塞，影响了整体效率。
        就好比一个企业里面有10个（core）正式工的名额，最多招10个正式工，要是任务超过正式工人数
        （task > core）的情况下，工厂领导（线程池）不是首先扩招工人，还是这10人，但是任务可以稍微积
        压一下，即先放到队列去（代价低）。10个正式工慢慢干，迟早会干完的，要是任务还在继续增加，超
        过正式工的加班忍耐极限了（队列满了），就的招外包帮忙了（注意是临时工）要是正式工加上外包还
        是不能完成任务，那新来的任务就会被领导拒绝了（线程池的拒绝策略）。

----------------------------------------

    **线程池中线程复用原理**

    在线程池中，同一个线程可以从阻塞队列中不断获取新任务来执行，其核心原理在于线程池对
    Thread 进行了封装，并不是每次执行任务都会调用 Thread.start() 来创建新线程，而是让每个线程去
    执行一个“循环任务”，在这个“循环任务”中不停检查是否有任务需要被执行，如果有则直接执行，也就是调用任务中的 run 方法，将 run 方法当成一个普通的方法执行，通过这种方式只使用固定的线程就将所有任务的 run 方法串联起来

19.  线程的生命周期

## 分布式

cap理论

数据一致性c
服务可用性a
分区容错性p

`cp -> zookeeper`

base理论

1、`基本可用`：允许可用性降低（可能响应延长、可能服务降级），
2、`软状态`：指允许系统中的数据存在中间状态，并认为该中间状态不会影响系统整体可用性。
2、`最终一致性`：节点数据同步可以存在时延），但在一定的期限后必须达成数据的一致，状态变为最终状态


常见的负载策略

1. 轮询法
2. 加权轮询法
3. 随机数
4. 加权随机数
5. 最小连接数
6. `原地址哈希法`


高并发: 
高可用：

1. 计算机硬件方面：
  根据需要适当提升计算机机器性能
  重要的应用 多个机房，创建多个服务集群

2. 使用负载均衡方式分流处理

3. 请求缓存解决方案--热点数据进行缓存处理

4. 请求合并方案--使用微服务组件，进行合并请求处理，减少线程网络磁盘io处理

5. sql优化，jvm优化，程序优化

6. 使用消息队列，流量削峰，异步处理等等

7. 使用微服务组件，进行限流处理

8. 可靠的监控平台，zabbix promethus 等等

----------------------------------------

分布式解决方案：
`xA` 

2pc：
第一阶段（ prepare ） ：每个参与者执行本地事务但不提交，进入 ready 状态，并通知协调者已经准备就绪。
二阶段（ commit ） 当协调者确认每个参与者都 ready 后，通知参与者进行 commit 操作；如果有参与者 fail ，则发送 rollback 命令，各参与者做回滚。

3pc:

第一阶段：CanCommit阶段，协调者询问事务参与者，是否有能力完成此次事务。如果都返回yes，则进入第二阶段有一个返回no或等待响应超时，则中断事务，并向所有参与者发送abort

请求第二阶段：PreCommit阶段，此时协调者会向所有的参与者发送PreCommit请求，参与者收到后开始执行事务操作。参与者执行完事务操作后（此时属于未提交事务的状态），就会向协调者反馈“Ack”表示我已经准备好提交了，并等待协调者的下一步指令。

第三阶段：DoCommit阶段， 在阶段二中如果所有的参与者节点都返回了Ack，那么协调者就会从“预提交状态”转变为“提交状态”。然后向所有的参与者节点发送"doCommit"请求，参与者节点在收到提交请求后就会各自执行事务提交操作，并向协调者节点反馈“Ack”消息，协调者收到所有参与者的Ack消息后完成事务。 相反，如果有一个参与者节点未完成PreCommit的反馈或者反馈超时，那么协调者都会向所有的参与者节点发送abort请求，从而中断事务。

`TCC`

本地创建事务表，或者创建事务标识，定时去对方查询数据事务是否执行成功失败；达到最终一致性

MQ消息队列模式



# 1. Kafka为什么⽐RocketMQ的吞吐量要⾼ 
Kafka的⽣产者采⽤的是异步发送消息机制，当发送⼀条消息时，消息并没有发送到Broker⽽是缓存起来，然后直接向业务返回成功，当缓存的消息达到⼀定数量时再批量发送给Broker。这种做法减少了⽹络io，从⽽提⾼了消息发送的吞吐量，但是如果消息⽣产者宕机，会导致消息丢失，业务出错，所以理 论上kafka利⽤此机制提⾼了性能却降低了可靠性。

# 2. Kafka的Pull和Push分别有什么优缺点 
    1. pull表示消费者主动拉取，可以批量拉取，也可以单条拉取，所以pull可以由消费者⾃⼰控制，根据 ⾃⼰的消息处理能⼒来进⾏控制，但是消费者不能及时知道是否有消息，可能会拉到的消息为空 
    2. push表示Broker主动给消费者推送消息，所以肯定是有消息时才会推送，但是消费者不能按⾃⼰的 能⼒来消费消息，推过来多少消息，消费者就得消费多少消息，所以可能会造成⽹络堵塞，消费者 压⼒⼤等问题

    ------------------------------------

    `pull模式`：
    根据consumer的消费能力进行数据拉取，可以控制速率
    `可以批量拉取、也可以单条拉取`
    可以设置不同的提交方式，实现不同的传输语义

    缺点：如果kafka没有数据，会导致consumer空循环，消耗资源
    解决：通过参数设置，consumer拉取数据为空或者没有达到一定数量时进行阻塞

    `push模式`：不会导致consumer循环等待

        缺点：速率固定、忽略了consumer的消费能力，可能导致拒绝服务或者网络拥塞等情况

# 3. Kafka、ActiveMQ、RabbitMQ、RocketMQ 对比

`ActiveMQ`：JMS规范，支持事务、支持XA协议，没有生产大规模支撑场景、官方维护越来越少

`RabbitMQ`：erlang语言开发、性能好、高并发，支持多种语言，社区、文档方面有优势，erlang语言
不利于java程序员二次开发，依赖开源社区的维护和升级，需要学习AMQP协议、学习成本相对较高
以上吞吐量单机都在万级

优点： 消息可靠性高，功能全面。
缺点：吞吐量比较低，消息积累会严重影响性能。erlang语言不好定制。
使用场景：小规模场景。

`kafka`：高性能，高可用，生产环境有大规模使用场景，单机容量有限（超过64个分区响应明显变
长）、社区更新慢
吞吐量单机百万

优点： 吞吐量非常大，性能非常好，集群高可用。
缺点：会丢数据，功能比较单一。

`rocketmq`：java实现，方便二次开发、设计参考了kafka，`高可用、高可靠`，社区活跃度一般、支持语
言较少
吞吐量单机十万

优点：高吞吐、高性能、高可用，功能非常全面。
缺点：开源版功能不如云上商业版。官方文档和周边生态还不够成熟。客户端只支
持java。
使用场景：几乎是全场景。




# 4. Kafka消息高可靠解决方案

消息发送：
ack：0、不重试，1、lead写入成功就返回了，`all/-1、等待ISR同步完再返回`
unclean.leader.election.enable : false，禁止选举ISR以外的follower为leader
tries > 1，重试次数
`min.insync.replicas > 1：同步副本数`，没满足该值前、不提供读写服务、写操作会异常

------------------------

消费：
`手工提交offset`
先commit再处理消息。如果在处理消息的时候异常了，但是offset 已经提交了，这条消息对于该消费者来 说就是丢失了，再也不会消费到了。

`broker：减小刷盘间隔`
`事务消息`


# 5. kafka高性能高吞吐的原因
  ## MQ如何保证消息的高效读写
1、`磁盘顺序读写`：保证了消息的堆积
顺序读写，磁盘会预读，预读即在读取的起始地址连续读取多个页面，主要时间花费在了传输时
间，而这个时间两种读写可以认为是一样的。
随机读写，因为数据没有在一起，将预读浪费掉了。需要多次寻道和旋转延迟。而这个时间可能是
传输时间的许多倍。
2、`零拷贝`：避免 CPU 将数据从一块存储拷贝到另外一块存储的技术
传统的数据复制：
1、读取磁盘文件数据到内核缓冲区
2、将内核缓冲区的数据copy到用户缓冲区
2、将用户缓冲区的数据copy到socket的发送缓冲区
3、将socket发送缓冲区中的数据发送到网卡、进行传输
零拷贝：
磁盘文件->内核空间读取缓冲区->网卡接口->消费者进程
3、`分区分段+索引`
Kafka的message消息实际上是分布式存储在一个一个小的segment中的，每次文件操作也是直接操
作的segment。为了进一步的查询优化，Kafka又默认为分段后的数据文件建立了索引文件，就是文件
系统上的.index文件。这种分区分段+索引的设计，不仅提升了数据读取的效率，同时也提高了数据操
作的并行度
4、`批量压缩：多条消息一起压缩，降低带宽`
5、`批量读写`
6、`直接操作page cache`，而不是JVM、避免GC耗时及对象创建耗时，且读写速度更高，进程重启、缓存也不会丢失


# 6. Kafka中zk的作用
/brokers/ids：临时节点，保存所有broker节点信息，存储broker的物理地址、版本信息、启动时间
等，节点名称为brokerID，broker定时发送心跳到zk，如果断开则该brokerID会被删除

/brokers/topics：临时节点，节点保存broker节点下所有的topic信息，每一个topic节点下包含一个固
定的partitions节点，partitions的子节点就是topic的分区，每个分区下保存一个state节点、保存着当
前leader分区和ISR的brokerID，state节点由leader创建，若leader宕机该节点会被删除，直到有新的
leader选举产生、重新生成state节点

/consumers/[group_id]/owners/[topic]/[broker_id-partition_id]：维护消费者和分区的注册关系
/consumers/[group_id]/offsets/[topic]/[broker_id-partition_id]：分区消息的消费进度Offset
client通过topic找到topic树下的state节点、获取leader的brokerID，到broker树中找到broker的物理地址，但是client不会直连zk，而是通过配置的broker获取到zk中的信息


# 7 如何保证消息消费的幂等性？
其实就是要方式消费者重复消费消息的问题。
所有MQ产品并没有提供主动解决幂等性的机制，需要由消费者自行控制。
RocketMQ： 给每个消息分配了个MessageID。这个MessageID就可以作为消费
者判断幂等的依据。这种方式不太建议。
最好的方式就是自己带一个有业务标识的ID，来进行幂等判断。OrderID
统一ID分配。


# 8 使用MQ如何保证分布式事务的最终一致性？
分布式事务：业务相关的多个操作，保证他们同时成功或者同时失败。
最终一致性： 与之对应的就是强一致性
MQ中要保护事务的最终一致性，就需要做到两点
1、`生产者要保证100%的消息投递。 事务消息机制`
2、`消费者这一端需要保证幂等消费。 唯一ID+ 业务自己实现幂等`
分布式MQ的三种语义：
at least once
at most once
exactly once：
RocketMQ 并不能保证exactly once。商业版本当中提供了exactly once的实现
机制。
kafka： 在最新版本的源码当中，提供了exactly once的demo。
RabbitMQ： erlang天生就成为了一种屏障。

# 9 MQ如何保证消息顺序

全局有序和局部有序： MQ只需要保证局部有序，不需要保证全局有序。生产者把一组有序的消息放到同一个队列当中，而消费者一次消费整个队列当中消息。

RocketMQ中有完整的设计，但是在RabbitMQ和Kafka当中，并没有完整的设计，需要自己进行设计。
RabbitMQ：要保证目标exchange只对应一个队列。并且一个队列只对应一个消费者。
Kafka: 生产者通过定制partition分配规则，将消息分配到同一个partition。 Topic只对应一个消费者。


# 10 rabbitmq的镜像队列原理

GM负责消息的广播，所有的GM组成gm_group，形成链表结构，负责监听相邻节点的状态，以及传递消息到相邻节点，master的GM收到消息时代表消息同步完成

mirror_queue_master/slave负责消息的处理，操作blockingQueue，Queue负责AMQP协议（commit、rollback、ack等）

master处理读写


将所有队列设置为镜像队列，即队列会被复制到各个节点，各个节点状态一致，RabbitMQ高可用集群就已经搭建好了,我们可以重启服务，查看其队列是否在从节点同步


# 11 MQ有什么用？有哪些具体的使用场景？
MQ： MessageQueue，消息队列。 队列是一种FIFO先进先出的数据结构。消息由生产者发送到MQ进行排队，然后由消费者对消息进行处理。QQ、 微信 就是典型的MQ场景。

MQ的作用主要有三个方面：

1、`异步`：
例子：快递。 快递员-> 菜鸟驿站<- 客户
作用：异步能提高系统的响应速度和吞吐量。

2、`解耦`：
例子：《Thinking in java》 -> 编辑社
作用：服务之间进行解耦，可以减少服务之间的影响，提高系统的稳定性和可扩展性。
另外，解耦之后可以实现数据分发。生产者发送一个消息后，可以由多个消费者来处理。

3、`削峰`：
例子：长江涨水->三峡大坝
作用：以稳定的系统资源应对突发的流量冲击。
MQ的缺点：
1、系统可用性降低： 一旦MQ宕机，整个业务就会产生影响。高可用
2、系统的复杂度提高： 引入MQ之后，数据链路就会变得很复杂。如何保证消息不丢失？消息不会重复调用？怎么保证消息的顺序性？、、、、、
3、数据一致性： A系统发消息，需要由B、C两个系统一同处理。如果B系统处理成功、C系统处理失败，这就会造成数据一致性的问题。



# 12 rabbitmq的死信队列、延迟队列原理

死信消息：
1. 消息被消费方否定确认，使用 channel.basicNack 或 channel.basicReject ，并且此时requeue 属性被设置为 false 。 
2. 消息在队列的存活时间超过设置的TTL时间。
3. 消息队列的消息数量已经超过最大队列长度。

那么该消息将成为死信消息。如果配置了死信队列信息，那么该消息将会被丢进死信队列中，如果没有配置，则该消息将会被丢弃
为每个需要使用死信的业务队列配置一个死信交换机，同一个项目的死信交换机可以共用一个，然后为
每个业务队列分配一个单独的routeKey，死信队列只不过是绑定在死信交换机上的队列，死信交换机也
不是什么特殊的交换机，只不过是用来接受死信的交换机，所以可以为任何类型【Direct、Fanout、Topic】

TTL：一条消息或者该队列中的所有消息的最大存活时间
如果一条消息设置了TTL属性或者进入了设置TTL属性的队列，那么这条消息如果在TTL设置的时间内没
有被消费，则会成为“死信”。如果同时配置了队列的TTL和消息的TTL，那么较小的那个值将会被使用。
只需要消费者一直消费死信队列里的消息

# 13 RabbitMQ如何保证消息的可靠性传输
`使用事务消息`
2、`使用消息确认机制`
`发送方确认`：
channel设置为`confirm模式`，则每条消息会被分配一个唯一id
消息投递成功，信道会发送ack给生产者，包含了id，**回调ConfirmCallback接口**
如果发生错误导致消息丢失，发生nack给生产者。**回调ReturnCallback接口**--`失败确认`
ack和nack只有一个触发，且只有一次，异步触发。可以继续发送消息

`消息持久化`

`接收方确认`：
声明队列时，指定noack=false，broker会等待`消费者手动返回ack`、才会删除消息，否则立刻删除
broker的ack没有超时机制，只会判断链接是否断开，如果断开、消息会被重新发送

# 14 RabbitMQ事务消息
通过对信道设置实现
1. channel.txSelect()；通知服务器开启事务模式；服务端会返回Tx.Select-Ok
2. channel.basicPublish；发送消息，可以是多条，可以是消费消息提交ack
3. channel.txCommit()提交事务；
4. channel.txRollback()回滚事务；

消费者使用事务：
1. autoAck=false，手动提交ack，以事务提交或回滚为准；
2. autoAck=true，不支持事务的，也就是说你即使在收到消息之后在回滚事务也是于事无补的，队列已经把消息移除了

如果其中任意一个环节出现问题，就会抛出IoException异常，用户可以拦截异常进行事务回滚，或决定要不要重复消息。`事务消息会降低rabbitmq的性能`


# 15 RocketMQ的底层实现原理  
## RocketMQ 架构设计
RocketMQ由`NameServer集群`、`Producer集群`、`Consumer集群`、`Broker集群`组成，
消息⽣产和消费 的⼤致原理如下： 
1. Broker在启动的时候向所有的NameServer注册，并保持⻓连接，每30s发送⼀次⼼跳 
2. Producer在发送消息的时候从NameServer获取Broker服务器地址，根据负载均衡算法选择⼀台服务器来发送消息 
3. Conusmer消费消息的时候同样从NameServer获取Broker地址，然后主动拉取消息来消费

NameServer为`producer和consumer提供路由信息`，`同时还有提供服务的注册和服务的剔除`


# 16 简述kafka的rebalance机制


# 17 简述kafka的副本同步机制

`每次数据写入时，只有 ISR 中的所有 Replica 都复制完，Leader 才会将其置为 Commit，它才能被 Consumer 所消费`


LEO：下一条待写入位置
firstUnstableOffset：第一条未提交数据
LastStableOffset：最后一条已提交数据
LogStartOffset：起始位置
isolation.level=read_committed：只能消费到LastStableOffset，read_committed可以消费到HW的
上一条
一个partition对应的ISR中最小的LEO作为分区的HW，`consumer最多只能消费到HW所在的位置`

leader收消息后会更新本地的LEO，leader还会维护follower的LEO即remote LEO，

follower发出fetch同步数据请求时(携带自身的LEO)、
leader会更新remote LEO，更新分区的HW，然后将数据响应给follower、
follower更新自身HW(取响应中的HW和自身的LEO中的较小值)，LEO+1
ISR：如果一个follower落后leader不超过某个时间阈值，那么则则ISR中，否则将放在OSR中。

同步副本时，follower获取leader的LEO和LogStartOffset，与本地对比、如果本地的LogStartOffset超
出了leader的值，则超过这个值的数据删除，再进行同步，如果本地的小于leader的、则直接同步


# 18 RocketMQ 顺序消息原理

默认是不能保证的，需要程序保证发送和消费的是同一个queue，多线程消费也无法保证
发送顺序：发送端自己业务逻辑保证先后，发往一个固定的queue，生产者可以在消息体上设置消息的
顺序
发送者实现MessageQueueSelector接口，选择一个queue进行发送，也可使用rocketmq提供的默认
实现
SelectMessageQueueByHash：按参数的hashcode与可选队列进行求余选择
SelectMessageQueueByRandom：随机选择
mq：queue本身就是顺序追加写，只需保证一个队列统一时间只有一个consumer消费，通过加锁实
现，consumer上的顺序消费有一个定时任务、每隔一定时间向broker发送请求延长锁定
消费端：
pull模式：消费者需要自己维护需要拉取的queue，一次拉取的消息都是顺序的，需要消费端自己保证
顺序消费
push模式：消费实例实现自MQPushConsumer接口，提供注册监听的方法消费消息，
registerMessageListener、重载方法
MessageListenerConcurrently ：并行消费
MessageListenerOrderly ：串行消费，consumer会把消息放入本地队列并加锁，定时任务保证锁的同步


# 19 kafka架构设计

`Consumer Group`：消费者组，消费者组内每个消费者负责消费不同分区的数据，提高消费能力。辑上的一个订阅者。

`Topic`：可以理解为一个队列，Topic 将消息分类，生产者和消费者面向的是同一个 Topic。

`Partition`：为了实现扩展性，提高并发能力，一个Topic 以多个Partition的方式分布到多个 Broker上，每个 Partition 是一个 有序的队列。一个 Topic 的每个Partition都有若干个副本（Replica），一个Leader 和若干个 Follower。生产者发送数据的对象，以及消费者消费数据的对象，都是 Leader。

Follower负责实时从 Leader 中同步数据，保持和 Leader 数据的同步。Leader 发生故障时，某个Follower 还会成为新的 Leader。

`Zookeeper`：Kafka 集群能够正常工作，需要依赖于 Zookeeper，Zookeeper 帮助 Kafka 存储和管理集群信息。


# 20  rabbitmq的持久化机制
1、交换机持久化：exchange_declare创建交互机时通过参数指定
2、队列持久化：queue_declare创建队列时通过参数指定
3、消息持久化：new AMQPMessage创建消息时通过参数指定

append的方式写文件，会根据大小自动生成新的文件，rabbitmq启动时会创建两个进程，一个负责持
久化消息的存储，另一个负责非持久化消息的存储(内存不够时)
消息存储时会在ets表中记录消息在文件中的映射以及相关信息（包括id、偏移量，有效数据，左边文
件，右边文件），消息读取时根据该信息到文件中读取、同时更新信息
消息删除时只从ets删除，变为垃圾数据，当垃圾数据超出比例（默认50%），并且文件数达到3个，触
发垃圾回收，锁定左右两个文件，整理左边文件有效数据、将右边文件有效数据写入左边，更新文件信
息，删除右边，完成合并。当一个文件的有用数据等于0时，删除该文件。
写入文件前先写buffer缓冲区，如果buffer已满，则写入文件(此时只是操作系统的页存)
每隔25ms刷一次磁盘，不管buffer满没满，都将buffer和页存中的数据落盘
每次消息写入后，如果没有后续写入请求，则直接刷盘
--------------------------

默认情况下，队列和交换器在服务器重启后都会消失，消息当然也是。
将`队列和交换器的 durable 属性设为 true，缺省为 false`，
但是消息要持久化还 不够，还需要将消息在发布前，将`投递模式设置为 2`。
消息要持久化，必须要有持久化的队列、交换器和投递模式都为 2。 消息属性的设置方法，包括如何将消息的持久化，参见代码


# 21 简述RabbitMq的交换机类型
交换器分发会先找出绑定的队列，然后再判断 routekey ，来决定是否将消息分发到某一个队列中
fanout：扇形交换机，不再判断routekey，直接将消息分发到所有绑定的队列
direct：判断routekey的规则是完全匹配模式，即发送消息时指定的routekey要等于绑定的routekey
topic：判断routekey的规则是模糊匹配模式
header：绑定队列与交换器的时候指定一个键值对，当交换器在分发消息的时候会先解开消息体里的
headers 数据，然后判断里面是否有所设置的键值对，如果发现匹配成功，才将消息分发到队列中；这
种交换器类型在性能上相对来说较差，在实际工作中很少会用到

# 22 RabbitMQ架构设计
`Broker`：rabbitmq的服务节点
`Queue`：队列，是RabbitMQ的内部对象，用于存储消息。RabbitMQ中消息只能存储在队列中。生产
者投递消息到队列，消费者从队列中获取消息并消费。多个消费者可以订阅同一个队列，这时队列中的
消息会被平均分摊(轮询)给多个消费者进行消费，而不是每个消费者都收到所有的消息进行消费。(注意：RabbitMQ不支持队列层面的广播消费，如果需要广播消费，可以采用一个交换器通过路由Key绑
定多个队列，由多个消费者来订阅这些队列的方式。
`Exchange`：交换器。生产者将消息发送到Exchange，由交换器将消息路由到一个或多个队列中。如果
路由不到，或返回给生产者，或直接丢弃，或做其它处理。
`RoutingKey`：路由Key。生产者将消息发送给交换器的时候，一般会指定一个RoutingKey，用来指定
这个消息的路由规则。这个路由Key需要与交换器类型和绑定键(BindingKey)联合使用才能最终生效。
在交换器类型和绑定键固定的情况下，生产者可以在发送消息给交换器时通过指定RoutingKey来决定消
息流向哪里。
`bindingKey`：通过绑定将交换器和队列关联起来，在绑定的时候一般会指定一个绑定键，这样
RabbitMQ就可以指定如何正确的路由到队列了。
交换器和队列实际上是多对多关系。就像关系数据库中的两张表。他们通过BindingKey做关联(多对多
关系表)。在投递消息时，可以通过Exchange和RoutingKey(对应BindingKey)就可以找到相对应的队
列。
`信道`：信道是建立在Connection 之上的虚拟连接。当应用程序与Rabbit Broker建立TCP连接的时候，
客户端紧接着可以创建一个AMQP 信道(Channel) ，每个信道都会被指派一个唯一的D。RabbitMQ 处
理的每条AMQP 指令都是通过信道完成的。信道就像电缆里的光纤束。一条电缆内含有许多光纤束，允
许所有的连接通过多条光线束进行传输和接收。

`vhost`：虚拟主机，每一个应用可以指定不同的vhost，此时对于应用来说、vhost就是broker


# 23 简述RocketMQ 持久化机制
commitLog：日志数据文件，被所有的queue共享，大小为1G，写满之后重新生成，顺序写
consumeQueue：逻辑queue，消息先到达commitLog、然后异步转发到consumeQueue，包含
queue 在 CommitLog 中的物理位置偏移量 Offset，消息实体内容的大小和 Message Tag 的
hash 值。大小约为 600W 个字节，写满之后重新生成，顺序写
indexFile：通过 key 或者时间区间来查找 CommitLog 中的消息，文件名以创建的时间戳命名，
固定的单个 IndexFile 大小为 400M，可以保存 2000W 个索引
所有队列共用一个日志数据文件，避免了kafka的分区数过多、日志文件过多导致磁盘IO读写压力较大
造成性能瓶颈，rocketmq的queue只存储少量数据、更加轻量化，对于磁盘的访问是串行化避免磁盘
竞争，缺点在于：写入是顺序写，但读是随机的，先读ConsumeQueue，再读 CommitLog，会降低消
息读的效率
消息发送到broker后，会被写入commitLog，写之前加锁，保证顺序写入。然后转发到
consumeQueue
消息消费时先从consumeQueue读取消息在 CommitLog 中的起始物理偏移量 Offset，消息大小、和
消息 Tag 的 HashCode 值。在从CommitLog 读取消息内容
同步刷盘，消息持久化到磁盘才会给生产者返回ack，可以保证消息可靠、但是会影响性能
异步刷盘：消息写入pageCache就返回ack给生产者，刷盘采用异步线程，降低读写延迟提高性能
和吞吐


# 24 让你设计一个MQ，你会如何设计？
两个误区： 1、 放飞自我，漫无边际。 2、纠结技术细节。
好的方式： 1、 从整体到细节，从业务场景到技术实现。2、以现有产品为基础。
RocketMQ
答题思路： MQ作用、项目大概的样子。
1、实现一个单机的队列数据结构。 高效、可扩展。
2、将单机队列扩展成为分布式队列。- 分布式集群管理
3、基于Topic定制消息路由策略。- 发送者路由策略，消费者与队列对应关系，消
费者路由策略
4、实现高效的网络通信。- Netty Http
5、规划日志文件，实现文件高效读写。- 零拷贝，顺序写。 服务重启后，快速还原
运行现场。
6、定制高级功能，死信队列、延迟队列、事务消息等等。 - 贴合实际，随意发挥。
